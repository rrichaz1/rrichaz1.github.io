The descriptive statistics is used to describe the basic features of data in a study. Doing exploratory data analysis, univariate and multivariate lays down the foundation for the Inferential statistics. It is very important to let the data speak for itself instead of fitting the data to some conclusion.

The different types of data are:
1.	Quantitative (apply parametric statistical methods)
a.	Ratio – can have true zero like weight. Absence of mass can result in 0 weight.
b.	Interval – cannot have true zero like temperature. 0 degree does not mean absence of heat. 
2.	Categorical (apply parametric statistical methods)
a.	Nominal – each category is equally important. It is used to label data
b.	Ordinal – the category has a priority e.g.  high, medium, low
3.	Text data – natural language.

It is very important to understand the structure of the data set so that we can apply the right statistical tools. The distribution of the data also plays a very important role in selecting the right statistical method. The parametric statistical methods work best when data can be modeled as Gaussian or normal distribution. 

Then we delved into Inferential statistics. As the name suggest, Inferential statistics use a random sample of data taken from a population to describe and make inferences about the population. Inferential statistics are valuable when examination of each member of an entire population is not convenient or possible

The basis of inferential statistics lies a great deal on central limit theorem. The central limit theorem states that the sampling distribution of the mean of any independent, random variable will be normal or nearly normal, if the sample size is large enough. Say we want to estimate the height of long-distance runners. Collect the weights of samples (recommended sample size > 30), calculate the mean of each sample. The plot of means of the sampling distribution (samples) will follow a normal distribution. The mean of means will be a good approximation of population mean (in this case the mean weight of the long-distance runners). 
The Standard deviation of the means of the samples is also called standard error. The bigger the sample size the smaller the standard error and better the inference.

My aha moment Bernoulli is just a special case of Binomial distribution. 
The question I am struggling with is – how do we apply these concepts to the project and to solve the real world problems.

Some references:
[https://www.youtube.com/watch?v=A82brFpdr9g](https://www.youtube.com/watch?v=A82brFpdr9g)
[https://stattrek.com/estimation/standard-error.aspx](https://stattrek.com/estimation/standard-error.aspx)
[https://reference.wolfram.com/language/guide/DescriptiveStatistics.html](https://reference.wolfram.com/language/guide/DescriptiveStatistics.html)
[https://towardsdatascience.com/understanding-the-central-limit-theorem-642473c63ad8](https://towardsdatascience.com/understanding-the-central-limit-theorem-642473c63ad8)
